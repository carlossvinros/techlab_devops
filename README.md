# Projeto de Rateio de Custos com IA

## ğŸ¯ VisÃ£o Geral do Projeto

Este projeto automatiza o processo de rateio de custos de uma empresa, consolidando dados de mÃºltiplas planilhas (colaboradores, ferramentas de software, benefÃ­cios) para gerar um relatÃ³rio final detalhado por colaborador. A principal caracterÃ­stica inteligente do sistema Ã© o uso de um Modelo de Linguagem Grande (LLM) para realizar o mapeamento semÃ¢ntico de colunas com nomes variados nas planilhas de entrada para um esquema padronizado.

O desenvolvimento foi guiado pela necessidade de criar uma soluÃ§Ã£o flexÃ­vel e adaptÃ¡vel, evitando scripts com lÃ³gica de tratamento de dados prÃ©-definida e inflexÃ­vel para a etapa de mapeamento.

## ğŸš€ SoluÃ§Ã£o Proposta

O sistema Ã© implementado em Python e segue um pipeline de trÃªs etapas principais:

1.  **Etapa 1: Leitura e Carregamento de Dados**
    * As planilhas de entrada no formato `.xlsx` (localizadas em `data/input/`) sÃ£o lidas utilizando a biblioteca Pandas e carregadas em DataFrames.

2.  **Etapa 2: Mapeamento Inteligente de Colunas com LLM**
    * Para cada planilha carregada, os nomes de suas colunas sÃ£o enviados a um Modelo de Linguagem Grande (LLM), especificamente o `llama3-8b-8192` acessado via API da Groq atravÃ©s do LiteLLM.
    * O LLM Ã© instruÃ­do a identificar as colunas que correspondem a conceitos chave (Nome do Colaborador, CPF, Custo Principal da Planilha) com base em sua compreensÃ£o semÃ¢ntica, mesmo que os nomes das colunas variem entre as planilhas.
    * O LLM retorna os nomes das colunas originais identificadas, que sÃ£o entÃ£o processados para criar um dicionÃ¡rio de mapeamento padronizado. Este dicionÃ¡rio guia a transformaÃ§Ã£o dos dados na etapa seguinte.

3.  **Etapa 3: ConsolidaÃ§Ã£o, CÃ¡lculo de Custos e GeraÃ§Ã£o do RelatÃ³rio**
    * Utilizando o mapeamento gerado na Etapa 2, os DataFrames sÃ£o padronizados (colunas renomeadas, CPFs limpos).
    * Os DataFrames padronizados sÃ£o unidos (merge) usando o CPF como chave principal.
    * SÃ£o calculados os custos individuais por colaborador para cada ferramenta e benefÃ­cio.
    * SÃ£o calculados subtotais para "Centro de Custo BenefÃ­cios" e "Centro de Custo Ferramentas".
    * O "Custo Geral Total" por colaborador Ã© calculado (incluindo salÃ¡rio e todos os outros custos).
    * Um relatÃ³rio final consolidado Ã© gerado como um arquivo `.xlsx` na pasta `data/output/`.


## ğŸ“‚ Estrutura do DiretÃ³rio
techlab_devops/
â”œâ”€â”€ .gitignore          # Especifica arquivos ignorados pelo Git
â”œâ”€â”€ README.md           
â”œâ”€â”€ requirements.txt    # DependÃªncias Python do projeto
â”œâ”€â”€ main.py             # Script principal para executar o pipeline
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ input/          # Local para colocar as planilhas .xlsx de entrada
â”‚   â”‚   â”œâ”€â”€ colaboradores.xlsx
â”‚   â”‚   â”œâ”€â”€ github.xlsx
â”‚   â”‚   â”œâ”€â”€ gympass.xlsx
â”‚   â”‚   â”œâ”€â”€ google_workspace.xlsx
â”‚   â”‚   â””â”€â”€ unimed.xlsx
â”‚   â””â”€â”€ output/         # Onde o relatÃ³rio final .xlsx serÃ¡ gerado
â”‚       â””â”€â”€ (Relatorio_Rateio_Custos.xlsx)
â”‚
â””â”€â”€ src/
â”œâ”€â”€ init.py
â”œâ”€â”€ data_handler.py     # FunÃ§Ãµes para carregar dados e consolidar/calcular
â”œâ”€â”€ agent_mapper.py     # LÃ³gica para interagir com o LLM e obter o mapeamento 
â””â”€â”€ report_generator.py # FunÃ§Ã£o para gerar o arquivo Excel final 

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python 3.9+**
* **Pandas:** Para manipulaÃ§Ã£o e anÃ¡lise de dados tabulares.
* **LiteLLM:** Para interaÃ§Ã£o simplificada com diversas APIs de LLMs.
* **Groq API:** Para acesso ao modelo de linguagem `llama3-8b-8192` (ou outro configurado).
* **python-dotenv:** Para gerenciamento de variÃ¡veis de ambiente (como chaves de API).
* **Openpyxl:** Utilizado internamente pelo Pandas para ler e escrever arquivos Excel (`.xlsx`).

*Nota sobre Frameworks de Agentes:* Durante o desenvolvimento, foi explorado o uso do framework CrewAI. No entanto, devido a desafios tÃ©cnicos na integraÃ§Ã£o especÃ­fica do LLM (Groq) com as abstraÃ§Ãµes de LLM do LangChain/CrewAI no ambiente de desenvolvimento, optou-se por uma interaÃ§Ã£o direta com o LLM via LiteLLM para a tarefa de mapeamento, mantendo o espÃ­rito de uma soluÃ§Ã£o "agente" onde o LLM realiza a tomada de decisÃ£o inteligente.

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

1.  **Clone o RepositÃ³rio:**
    ```bash
    git clone https://github.com/carlossvinros/techlab_devops
    cd techlab_devops
    ```

2.  **Crie e Ative um Ambiente Virtual (Recomendado):**
    ```bash
    python -m venv .venv
    source .venv/bin/activate  # No Linux/macOS
    # .venv\Scripts\activate    # No Windows
    ```

3.  **Instale as DependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure as VariÃ¡veis de Ambiente:**
    * Crie um arquivo chamado `.env` na raiz do projeto.
    * Adicione suas credenciais da API Groq e o nome do modelo:
      ```env
      GROQ_API_KEY="sua_chave_api_real_da_groq_aqui"
      GROQ_MODEL_NAME="llama3-8b-8192" # Exemplo
      ```
    * **Importante:** Substitua `"sua_chave_api_real_da_groq_aqui"` pela sua chave de API vÃ¡lida da Groq. O modelo `llama3-8b-8192` Ã© um exemplo; use o modelo configurado no seu ambiente Groq.

## â–¶ï¸ Como Executar

1.  **Prepare os Arquivos de Entrada:**
    * Coloque as 5 planilhas Excel (`colaboradores.xlsx`, `github.xlsx`, `gympass.xlsx`, `google_workspace.xlsx`, `unimed.xlsx`) dentro da pasta `data/input/`.
    * Certifique-se de que os nomes dos arquivos e as colunas relevantes dentro deles correspondem semanticamente ao que o LLM foi instruÃ­do a procurar (conforme detalhado nos prompts em `src/agent_mapper.py`).

2.  **Execute o Script Principal:**
    A partir da raiz do projeto, execute:
    ```bash
    python main.py
    ```

3.  **Verifique a SaÃ­da:**
    * Acompanhe os logs no terminal para o progresso de cada etapa.
    * O relatÃ³rio final, chamado `Relatorio_Rateio_Custos.xlsx` (ou o nome definido em `main.py`), serÃ¡ gerado na pasta `data/output/`.
    * Logs de execuÃ§Ã£o detalhados de cada chamada ao LLM para mapeamento de planilhas (se o `output_log_file` estiver ativo no `Crew` dentro do `agent_mapper.py` - atualmente Ã© dinÃ¢mico) podem ser encontrados como `crew_log_<nome_planilha>.json`.

## ğŸ“Š Formato dos Dados

* **Entrada:** 5 arquivos Excel (`.xlsx`). O sistema espera que as colunas contenham informaÃ§Ãµes semanticamente relacionadas a nomes de colaboradores, CPFs e valores de custos/salÃ¡rios, mesmo que os cabeÃ§alhos exatos das colunas variem.
* **SaÃ­da (`Relatorio_Rateio_Custos.xlsx`):**
    * `CPF_Padronizado`
    * `Nome_Padronizado`
    * `Departamento` 
    * `Salario_Base`
    * `Custo_GitHub`
    * `Custo_GoogleWorkspace`
    * `Centro_Custo_Ferramentas` (soma dos custos de GitHub e Google Workspace)
    * `Custo_Gympass`
    * `Custo_Unimed`
    * `Centro_Custo_Beneficios` (soma dos custos de Gympass e Unimed)
    * `Custo_Geral_Total` (soma do SalÃ¡rio Base e todos os custos individuais de ferramentas e benefÃ­cios)


## ğŸ§  O Papel do Agente de IA

Embora a implementaÃ§Ã£o final para a interaÃ§Ã£o com o LLM utilize chamadas diretas via LiteLLM em vez da estrutura formal de `Agent` do framework CrewAI (decisÃ£o tomada devido a desafios de integraÃ§Ã£o especÃ­ficos), o sistema ainda emprega um componente de IA de forma "agente". O LLM atua como o "cÃ©rebro" para a tarefa de mapeamento semÃ¢ntico, interpretando os nomes das colunas e tomando decisÃµes sobre como padronizÃ¡-los. O cÃ³digo Python ao redor orquestra essas chamadas e aplica as decisÃµes do LLM, cumprindo o requisito do desafio de usar IA para um tratamento de dados nÃ£o-fixo e inteligente.